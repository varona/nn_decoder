{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a ResNet neural-network decoder\n",
    "\n",
    "We will now train a ResNet50 model to decode a code of length 5 subject to independent bit- and phase-flip noise ('uncorrelated') near the threshold error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PATH = '../Python' # path to src\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from hexagonal_lattice import HexagonalLattice\n",
    "\n",
    "sys.path.append(os.path.abspath(SRC_PATH))\n",
    "lattice = HexagonalLattice(5,5) #Â Code on a lattice of length 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "First, we will need to create the pattern data and the training data if they were not created before (this may take a few hours depending on your computer and the dataset size, see README files and other notebooks for more information). Pattern data can be obtained by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern data ready.\n"
     ]
    }
   ],
   "source": [
    "import compute_pattern as cp\n",
    "cp.compute_all_patterns(max_length=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be initially trained on a small dataset with low error rate and then trained with an error rate near the threshold value. `main_data_gen` generates training data and stores it in files, each containing $10^5$ examples. Below we generate 100 files with error rate $p_0=0.023$, corresponding to the initial training dataset, 1000 files for the main dataset with $p_0=0.048$ and 2 files for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing size=5, p_error=0.023, noise_type=uncorrelated ...\n",
      "Done!\n",
      "Computing size=5, p_error=0.048, noise_type=uncorrelated ...\n",
      "Done!\n",
      "Computing size=5, p_error=0.048, noise_type=uncorrelated ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../training_data'\n",
    "\n",
    "from data import main_data_gen\n",
    "# Initial training data\n",
    "main_data_gen(lattice, p_error=0.023, noise_type='uncorrelated', \n",
    "              start=0, end=50, data_type='initial',\n",
    "              path=DATA_PATH)\n",
    "# Main training data\n",
    "main_data_gen(lattice, p_error=0.048, noise_type='uncorrelated', \n",
    "              start=0, end=1000, data_type='data',\n",
    "              path=DATA_PATH)\n",
    "# Validation data\n",
    "main_data_gen(lattice, p_error=0.048, noise_type='uncorrelated', \n",
    "              start=0, end=2, data_type='validation',\n",
    "              path=DATA_PATH)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "Once we have the data, we can train the model. We use a ResNet model with some particularities (no downsampling, periodic padding...), making it more suitable for the characteristics of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from resnet import resnet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "input_shape = (lattice.N_row*2, lattice.N_col*2, np.int64(1))\n",
    "model = resnet(input_shape, depth=50, num_classes=16)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset may not fit into memory, thus we use a Sequence class to load data on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_utilities import DataLoader, data2image, EarlyStopping\n",
    "from functools import partial\n",
    "\n",
    "data_modifyer = partial(\n",
    "    data2image, lattice_shape=(lattice.N_row, lattice.N_col))\n",
    "\n",
    "initial = DataLoader((5,5), 'uncorrelated', batch_size=1000, \n",
    "    p_error=0.023, path=DATA_PATH, data_modifyer=data_modifyer, \n",
    "    data_type='initial')\n",
    "\n",
    "training = DataLoader((5,5), 'uncorrelated', batch_size=1000,\n",
    "    p_error=0.048, path=DATA_PATH, data_modifyer=data_modifyer, \n",
    "    data_type='data')\n",
    "\n",
    "validation = DataLoader((5,5), 'uncorrelated', batch_size=1000, \n",
    "    p_error=0.048, path=DATA_PATH, data_modifyer=data_modifyer, \n",
    "    data_type='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overfitting, the data is only fed once during training. Thus, we produce enough data to train the model on a single epoch. We define a callback to reduce learning rate when accuracy has stopped improving, accuracy is checked every 2000 steps. Likewise, another callback stops the training when the accuracy does not improve for a certain number of periods. Finally we also periodically compute val_acc and save the model every time val_acc improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 290s 58ms/step - loss: 0.2582 - acc: 0.9235\n",
      "  2000/100000 [..............................] - ETA: 1:34:39 - loss: 0.8717 - acc: 0.6709\n",
      "val_loss: 0.8553, val_acc: 0.6795, batch: 2000. Saved.\n",
      "\n",
      "  4000/100000 [>.............................] - ETA: 1:35:40 - loss: 0.8491 - acc: 0.6873\n",
      "val_loss: 0.8236, val_acc: 0.6893, batch: 4000. Saved.\n",
      "\n",
      "  6000/100000 [>.............................] - ETA: 1:33:40 - loss: 0.8346 - acc: 0.6957\n",
      "val_loss: 0.8136, val_acc: 0.6951, batch: 6000. Saved.\n",
      "\n",
      "  8000/100000 [=>............................] - ETA: 1:31:40 - loss: 0.8240 - acc: 0.7008\n",
      "val_loss: 0.7929, val_acc: 0.7006, batch: 8000. Saved.\n",
      "\n",
      " 10000/100000 [==>...........................] - ETA: 1:29:41 - loss: 0.8157 - acc: 0.7043\n",
      "val_loss: 0.7866, val_acc: 0.7037, batch: 10000. Saved.\n",
      "\n",
      " 12000/100000 [==>...........................] - ETA: 1:27:42 - loss: 0.8090 - acc: 0.7071\n",
      "val_loss: 0.7779, val_acc: 0.7061, batch: 12000. Saved.\n",
      "\n",
      " 14000/100000 [===>..........................] - ETA: 1:25:42 - loss: 0.8032 - acc: 0.7094\n",
      "val_loss: 0.7766, val_acc: 0.7081, batch: 14000. Saved.\n",
      "\n",
      " 16000/100000 [===>..........................] - ETA: 1:23:42 - loss: 0.7983 - acc: 0.7107\n",
      "val_loss: 0.7692, val_acc: 0.7107, batch: 16000. Saved.\n",
      "\n",
      " 18000/100000 [====>.........................] - ETA: 1:21:42 - loss: 0.7940 - acc: 0.7127\n",
      "val_loss: 0.7666, val_acc: 0.7096, batch: 18000.\n",
      "\n",
      " 20000/100000 [=====>........................] - ETA: 1:19:42 - loss: 0.7902 - acc: 0.7133\n",
      "val_loss: 0.7591, val_acc: 0.7132, batch: 20000. Saved.\n",
      "\n",
      " 22000/100000 [=====>........................] - ETA: 1:17:42 - loss: 0.7869 - acc: 0.7143\n",
      "val_loss: 0.7606, val_acc: 0.7141, batch: 22000. Saved.\n",
      "\n",
      " 24000/100000 [======>.......................] - ETA: 1:15:43 - loss: 0.7840 - acc: 0.7157\n",
      "val_loss: 0.7583, val_acc: 0.7126, batch: 24000.\n",
      "\n",
      " 26000/100000 [======>.......................] - ETA: 1:13:43 - loss: 0.7813 - acc: 0.7157\n",
      "val_loss: 0.7533, val_acc: 0.7142, batch: 26000. Saved.\n",
      "\n",
      " 28000/100000 [=======>......................] - ETA: 1:11:44 - loss: 0.7788 - acc: 0.7166\n",
      "val_loss: 0.7593, val_acc: 0.7132, batch: 28000.\n",
      "\n",
      " 30000/100000 [========>.....................] - ETA: 1:09:44 - loss: 0.7765 - acc: 0.7174\n",
      "val_loss: 0.7500, val_acc: 0.7159, batch: 30000. Saved.\n",
      "\n",
      " 32000/100000 [========>.....................] - ETA: 1:07:44 - loss: 0.7744 - acc: 0.7181\n",
      "val_loss: 0.7490, val_acc: 0.7164, batch: 32000. Saved.\n",
      "\n",
      " 34000/100000 [=========>....................] - ETA: 1:05:45 - loss: 0.7726 - acc: 0.7179\n",
      "val_loss: 0.7499, val_acc: 0.7158, batch: 34000.\n",
      "\n",
      " 36000/100000 [=========>....................] - ETA: 1:03:45 - loss: 0.7708 - acc: 0.7183\n",
      "Epoch 36001: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
      "\n",
      "val_loss: 0.7453, val_acc: 0.7164, batch: 36000.\n",
      "\n",
      " 38000/100000 [==========>...................] - ETA: 1:01:46 - loss: 0.7683 - acc: 0.7240\n",
      "val_loss: 0.7241, val_acc: 0.7233, batch: 38000. Saved.\n",
      "\n",
      " 40000/100000 [===========>..................] - ETA: 59:47 - loss: 0.7659 - acc: 0.7254\n",
      "val_loss: 0.7221, val_acc: 0.7242, batch: 40000. Saved.\n",
      "\n",
      " 42000/100000 [===========>..................] - ETA: 57:47 - loss: 0.7637 - acc: 0.7246\n",
      "val_loss: 0.7201, val_acc: 0.7245, batch: 42000. Saved.\n",
      "\n",
      " 44000/100000 [============>.................] - ETA: 55:48 - loss: 0.7616 - acc: 0.7255\n",
      "Epoch 44001: ReduceLROnPlateau reducing learning rate to 0.00010000000639606199.\n",
      "\n",
      "val_loss: 0.7193, val_acc: 0.7247, batch: 44000. Saved.\n",
      "\n",
      " 46000/100000 [============>.................] - ETA: 53:49 - loss: 0.7594 - acc: 0.7269\n",
      "val_loss: 0.7114, val_acc: 0.7273, batch: 46000. Saved.\n",
      "\n",
      " 48000/100000 [=============>................] - ETA: 51:49 - loss: 0.7573 - acc: 0.7282\n",
      "val_loss: 0.7105, val_acc: 0.7275, batch: 48000. Saved.\n",
      "\n",
      " 50000/100000 [==============>...............] - ETA: 49:50 - loss: 0.7553 - acc: 0.7286\n",
      "val_loss: 0.7090, val_acc: 0.7274, batch: 50000.\n",
      "\n",
      " 52000/100000 [==============>...............] - ETA: 47:50 - loss: 0.7534 - acc: 0.7287\n",
      "val_loss: 0.7081, val_acc: 0.7274, batch: 52000.\n",
      "\n",
      " 54000/100000 [===============>..............] - ETA: 45:51 - loss: 0.7516 - acc: 0.7283\n",
      "Epoch 54001: ReduceLROnPlateau reducing learning rate to 3.1622778103685084e-05.\n",
      "\n",
      "val_loss: 0.7074, val_acc: 0.7282, batch: 54000. Saved.\n",
      "\n",
      " 56000/100000 [===============>..............] - ETA: 43:51 - loss: 0.7500 - acc: 0.7285\n",
      "val_loss: 0.7058, val_acc: 0.7282, batch: 56000.\n",
      "\n",
      " 58000/100000 [================>.............] - ETA: 41:51 - loss: 0.7484 - acc: 0.7292\n",
      "val_loss: 0.7053, val_acc: 0.7285, batch: 58000. Saved.\n",
      "\n",
      " 60000/100000 [=================>............] - ETA: 39:52 - loss: 0.7469 - acc: 0.7295\n",
      "val_loss: 0.7048, val_acc: 0.7287, batch: 60000. Saved.\n",
      "\n",
      " 62000/100000 [=================>............] - ETA: 37:52 - loss: 0.7455 - acc: 0.7294\n",
      "Epoch 62001: ReduceLROnPlateau reducing learning rate to 1.0000000409520217e-05.\n",
      "\n",
      "val_loss: 0.7046, val_acc: 0.7287, batch: 62000.\n",
      "\n",
      " 64000/100000 [==================>...........] - ETA: 35:52 - loss: 0.7441 - acc: 0.7294\n",
      "val_loss: 0.7041, val_acc: 0.7287, batch: 64000.\n",
      "\n",
      " 66000/100000 [==================>...........] - ETA: 33:53 - loss: 0.7429 - acc: 0.7293\n",
      "Epoch 66001: ReduceLROnPlateau reducing learning rate to 3.1622778678900043e-06.\n",
      "\n",
      "val_loss: 0.7040, val_acc: 0.7290, batch: 66000. Saved.\n",
      "\n",
      " 68000/100000 [===================>..........] - ETA: 31:53 - loss: 0.7417 - acc: 0.7294\n",
      "val_loss: 0.7038, val_acc: 0.7288, batch: 68000.\n",
      "\n",
      " 70000/100000 [====================>.........] - ETA: 29:54 - loss: 0.7406 - acc: 0.7299\n",
      "val_loss: 0.7037, val_acc: 0.7290, batch: 70000. Saved.\n",
      "\n",
      " 72000/100000 [====================>.........] - ETA: 27:54 - loss: 0.7395 - acc: 0.7296\n",
      "val_loss: 0.7037, val_acc: 0.7289, batch: 72000.\n",
      "\n",
      " 74000/100000 [=====================>........] - ETA: 25:54 - loss: 0.7385 - acc: 0.7296\n",
      "Epoch 74001: ReduceLROnPlateau reducing learning rate to 1.0000000553323957e-06.\n",
      "\n",
      "val_loss: 0.7037, val_acc: 0.7292, batch: 74000. Saved.\n",
      "\n",
      " 76000/100000 [=====================>........] - ETA: 23:55 - loss: 0.7375 - acc: 0.7302\n",
      "val_loss: 0.7036, val_acc: 0.7289, batch: 76000.\n",
      "\n",
      " 78000/100000 [======================>.......] - ETA: 21:55 - loss: 0.7366 - acc: 0.7299\n",
      "Epoch 78001: ReduceLROnPlateau reducing learning rate to 3.162278011693743e-07.\n",
      "\n",
      "val_loss: 0.7036, val_acc: 0.7290, batch: 78000.\n",
      "\n",
      " 80000/100000 [=======================>......] - ETA: 19:56 - loss: 0.7357 - acc: 0.7300\n",
      "val_loss: 0.7036, val_acc: 0.7289, batch: 80000.\n",
      "\n",
      " 82000/100000 [=======================>......] - ETA: 17:56 - loss: 0.7349 - acc: 0.7299\n",
      "Epoch 82001: ReduceLROnPlateau reducing learning rate to 1.0000001452097325e-07.\n",
      "\n",
      "val_loss: 0.7036, val_acc: 0.7289, batch: 82000.\n",
      "\n",
      " 84000/100000 [========================>.....] - ETA: 15:56 - loss: 0.7341 - acc: 0.7298\n",
      "val_loss: 0.7036, val_acc: 0.7288, batch: 84000.\n",
      "\n",
      " 86000/100000 [========================>.....] - ETA: 13:57 - loss: 0.7333 - acc: 0.7300Early stopping: val_acc did not improve. Before: 0.7302, afer: 0.7300, diff = -0.0002.\n",
      "\n",
      "\n",
      "Epoch 86001: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "val_loss: 0.7036, val_acc: 0.7288, batch: 86000.\n",
      "\n",
      " 88000/100000 [=========================>....] - ETA: 11:57 - loss: 0.7326 - acc: 0.7295Early stopping: val_acc did not improve. Before: 0.7302, afer: 0.7295, diff = -0.0007.\n",
      "\n",
      "\n",
      "val_loss: 0.7036, val_acc: 0.7288, batch: 88000.\n",
      "\n",
      " 90000/100000 [==========================>...] - ETA: 9:58 - loss: 0.7320 - acc: 0.7297Early stopping: val_acc did not improve. Before: 0.7302, afer: 0.7297, diff = -0.0005.\n",
      "\n",
      "\n",
      "Epoch 90001: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "val_loss: 0.7036, val_acc: 0.7288, batch: 90000.\n",
      "\n",
      " 92000/100000 [==========================>...] - ETA: 7:58 - loss: 0.7313 - acc: 0.7297Early stopping: val_acc did not improve. Before: 0.7302, afer: 0.7297, diff = -0.0005.\n",
      "\n",
      "\n",
      "val_loss: 0.7036, val_acc: 0.7289, batch: 92000.\n",
      "\n",
      " 94000/100000 [===========================>..] - ETA: 5:58 - loss: 0.7307 - acc: 0.7297Early stopping: val_acc did not improve. Before: 0.7302, afer: 0.7297, diff = -0.0005.\n",
      "\n",
      "\n",
      "Epoch 94001: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "val_loss: 0.7036, val_acc: 0.7288, batch: 94000.\n",
      "\n",
      " 96000/100000 [===========================>..] - ETA: 3:59 - loss: 0.7301 - acc: 0.7295Early stopping: val_acc did not improve. Before: 0.7302, afer: 0.7295, diff = -0.0007.\n",
      "\n",
      "\n",
      "val_loss: 0.7036, val_acc: 0.7288, batch: 96000.\n",
      "\n",
      " 98000/100000 [============================>.] - ETA: 1:59 - loss: 0.7296 - acc: 0.7294Early stopping: val_acc did not improve. Before: 0.7302, afer: 0.7294, diff = -0.0008.\n",
      "\n",
      "\n",
      "Epoch 98001: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "val_loss: 0.7036, val_acc: 0.7288, batch: 98000.\n",
      "\n",
      "100000/100000 [==============================] - 5985s 60ms/step - loss: 0.7290 - acc: 0.7295 - val_loss: 0.7036 - val_acc: 0.7289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa62c35c860>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models_utilities import ReduceLROnPlateau, EarlyStopping, CustomSaver\n",
    "\n",
    "early_stopper = EarlyStopping(monitor='acc',\n",
    "    batch_period=2000, patience=5)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='acc', factor=np.sqrt(0.1), \n",
    "    patience=2, min_delta=4e-4, min_lr=1e-7, batch_period=2000)\n",
    "custom_saver = CustomSaver(validation, '5_5_uncorr_resnet', \n",
    "    batch_period=2000)\n",
    "callbacks = [lr_reducer, custom_saver, early_stopper]\n",
    "\n",
    "model.fit_generator(initial, epochs=1, workers=4,\n",
    "    use_multiprocessing=True, shuffle=True) \n",
    "\n",
    "h = model.fit_generator(training, epochs=1, \n",
    "    callbacks=callbacks, validation_data=validation, workers=4, \n",
    "    use_multiprocessing=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evolution of the validation loss and accuracy is recorded in `custom_saver.history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'val_loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "x = custom_saver.history['batch']\n",
    "y1 = custom_saver.history['val_acc']\n",
    "y2 = custom_saver.history['val_loss']\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(x, y1, 'g-')\n",
    "ax2.plot(x, y2, 'b-')\n",
    "\n",
    "ax1.set_xlabel('steps')\n",
    "ax1.set_ylabel('val_acc', color='g')\n",
    "ax2.set_ylabel('val_loss', color='b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
